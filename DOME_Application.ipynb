{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d878e8",
   "metadata": {},
   "source": [
    "## 1. Comment-Intent Labeling Tool (COIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329ac926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.comment_classifier.model import commentClassifier\n",
    "from transformers import AutoTokenizer\n",
    "import string\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a06814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin_preprocess(tokenizer, comment):\n",
    "    def count_punc_num(comment, comment_len):\n",
    "        count = lambda l1, l2: sum([1 for x in l1 if x in l2])\n",
    "        punc_num = count(comment, set(string.punctuation))\n",
    "        digits_num = count(comment, set(string.digits))\n",
    "        return (punc_num + digits_num) / comment_len\n",
    "\n",
    "    comment_tokens = tokenizer.tokenize(comment)\n",
    "    cc_tokens = [tokenizer.cls_token] + comment_tokens + [tokenizer.sep_token]\n",
    "    cc_ids = tokenizer.convert_tokens_to_ids(cc_tokens)\n",
    "    cc_att_mask = [1] * len(cc_tokens)\n",
    "    punc_num = count_punc_num(comment, len(comment.strip().split()))\n",
    "    if len(comment.strip().split()) < 3:\n",
    "        comment_len = 1\n",
    "    else:\n",
    "        comment_len = 0    \n",
    "    return torch.tensor(cc_ids).unsqueeze(0), torch.tensor(cc_att_mask).unsqueeze(0), \\\n",
    "           torch.tensor(comment_len).unsqueeze(0), torch.tensor(punc_num).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a2262",
   "metadata": {},
   "source": [
    "### COIN can identify the developer-intent for a given comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb1fb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load the parameters of the pretrained classifier!\n"
     ]
    }
   ],
   "source": [
    "# 1. load the well-trained COIN\n",
    "classifier = commentClassifier('./src/comment_classifier/pretrained_codebert', 6, 0.2)\n",
    "classifier.load_state_dict(torch.load(\"./src/comment_classifier//saved_model/comment_classifier.pkl\"))\n",
    "classifier.cuda()\n",
    "print(\"load the parameters of the pretrained classifier!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0a4ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. input a comment and preprocess it\n",
    "comment1 = 'Starts the background initialization'\n",
    "comment2 = 'After the construction of a BackgroundInitializer() object it start() method has to be called .'\n",
    "tokenizer = AutoTokenizer.from_pretrained('./src/comment_classifier/pretrained_codebert')\n",
    "cc_ids1, cc_att_mask1, comment_len1, punc_num1 = coin_preprocess(tokenizer, comment1)\n",
    "cc_ids2, cc_att_mask2, comment_len2, punc_num2 = coin_preprocess(tokenizer, comment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba389bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment: Starts the background initialization \n",
      "intent: what\n"
     ]
    }
   ],
   "source": [
    "# 3. predict the intent for the comment\n",
    "classifier.eval()\n",
    "class_name = ['what', 'why', 'how-to-use', 'how-it-is-done', 'property', 'others']\n",
    "logits1 = classifier(cc_ids1.cuda(), cc_att_mask1.cuda(), comment_len1.cuda(), punc_num1.cuda())\n",
    "prediction1 = class_name[int(torch.argmax(logits1, 1))]\n",
    "print('comment:', comment1, '\\nintent:', prediction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c549490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment: After the construction of a BackgroundInitializer() object it start() method has to be called . \n",
      "intent: how-to-use\n"
     ]
    }
   ],
   "source": [
    "logits2 = classifier(cc_ids2.cuda(), cc_att_mask2.cuda(), comment_len2.cuda(), punc_num2.cuda())\n",
    "prediction2 = class_name[int(torch.argmax(logits2, 1))]\n",
    "print('comment:', comment2, '\\nintent:', prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d98e54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "021b6fc3",
   "metadata": {},
   "source": [
    "## 2. Developer-Intent Driven Comment Generator (DOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae762e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.comment_generator.DOME import Generator\n",
    "from tokenizers import Tokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e9628",
   "metadata": {},
   "source": [
    "### DOME can generate various comments that are coherent with the given intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d88f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load the parameters of the pretrained generator!\n"
     ]
    }
   ],
   "source": [
    "# 1. load the well-trained DOME\n",
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.bpe_model = f'./src/Application_Demo/bpe_tokenizer_all_token.json'\n",
    "        self.tokenizer = Tokenizer.from_file(self.bpe_model)\n",
    "        self.vocab_size = self.tokenizer.get_vocab_size()\n",
    "        self.eos_token = self.tokenizer.token_to_id('[EOS]')\n",
    "        self.intent2id = {'what': 0, 'why': 1, 'usage': 2, 'done': 3, 'property': 4}\n",
    "        self.intent2bos_id = {'what': \"[WHAT/]\", 'why': \"[WHY/]\", 'usage': \"[USAGE/]\", 'done': \"[DONE/]\", 'property': \"[PROP/]\"}\n",
    "        self.intent2cls_id = {'what': \"[/WHAT]\", 'why': \"[/WHY]\", 'usage': \"[/USAGE]\", 'done': \"[/DONE]\", 'property': \"[/PROP]\"}\n",
    "\n",
    "        self.d_model = 512\n",
    "        self.d_intent = 128\n",
    "        self.d_ff = 2048\n",
    "        self.head_num = 8\n",
    "        self.enc_layer_num = 6\n",
    "        self.dec_layer_num = 6\n",
    "        self.max_token_inline = 25\n",
    "        self.max_line_num = 15\n",
    "        self.max_comment_len = 30\n",
    "        self.clip_dist_code = 8\n",
    "        self.intent_num = 5\n",
    "        self.stat_k = 5\n",
    "        self.token_k = 10\n",
    "        self.beam_width = 5\n",
    "        self.batch_size = 64\n",
    "        self.dropout = 0.2\n",
    "    \n",
    "config = Config()\n",
    "generator = Generator(config.d_model, config.d_intent, config.d_ff, config.head_num, config.enc_layer_num,\n",
    "                      config.dec_layer_num, config.vocab_size, config.max_comment_len, config.clip_dist_code, config.eos_token,\n",
    "                      config.intent_num, config.stat_k, config.token_k, config.dropout, None)\n",
    "generator.load_state_dict(torch.load(f\"./src/comment_generator/saved_model/tlcodesum/comment_generator.pkl\"))\n",
    "generator.cuda()\n",
    "print(\"load the parameters of the pretrained generator!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cba048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. load the data\n",
    "with open('./src/Application_Demo/demo_generator_dataset/raw_code.demo', 'r') as f:\n",
    "    raw_code_lines = f.readlines()\n",
    "with open('./src/Application_Demo/demo_generator_dataset/code_split.demo', 'r') as f:\n",
    "    code_stat_lines = f.readlines()\n",
    "with open('./src/Application_Demo/demo_generator_dataset/similar_comment.demo', 'r') as f:\n",
    "    similar_comment_lines = f.readlines()\n",
    "\n",
    "raw_code, input_code, code_valid_len, input_exemplar = [], [], [], []\n",
    "for raw_code_line, code_stat_line, exemplar_line in zip(raw_code_lines, code_stat_lines, similar_comment_lines):\n",
    "    raw_code.append(json.loads(raw_code_line.strip())['raw_code'])\n",
    "    statement_line = json.loads(code_stat_line.strip())\n",
    "    exemplar_what = json.loads(exemplar_line.strip())['what']\n",
    "    exemplar_why = json.loads(exemplar_line.strip())['why']\n",
    "    exemplar_done = json.loads(exemplar_line.strip())['done']\n",
    "    exemplar_usage = json.loads(exemplar_line.strip())['usage']\n",
    "    exemplar_property = json.loads(exemplar_line.strip())['property']\n",
    "    input_exemplar.append({'what':config.tokenizer.encode(exemplar_what).ids[:config.max_comment_len], 'why':config.tokenizer.encode(exemplar_why).ids[:config.max_comment_len], 'done':config.tokenizer.encode(exemplar_done).ids[:config.max_comment_len], 'usage':config.tokenizer.encode(exemplar_usage).ids[:config.max_comment_len], 'property':config.tokenizer.encode(exemplar_property).ids[:config.max_comment_len]})\n",
    "    \n",
    "    temp_code = []\n",
    "    for stat_idx, stat in enumerate(statement_line['code'][:config.max_line_num]):\n",
    "        cur_stat = config.tokenizer.encode(stat).ids[:config.max_token_inline]\n",
    "        temp_code = temp_code + cur_stat + [config.tokenizer.token_to_id('[PAD]')] * (config.max_token_inline - len(cur_stat))\n",
    "    input_code.append(temp_code)\n",
    "    \n",
    "    code_valid_len.append(len(statement_line['code'][:config.max_line_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a64cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(code, exemplar, intent, code_valid_len):\n",
    "    input_intent = torch.tensor(config.intent2id[intent]).unsqueeze(0).cuda()\n",
    "    bos = torch.tensor([config.tokenizer.token_to_id(config.intent2bos_id[intent])]).unsqueeze(0).cuda()\n",
    "    input_code = torch.tensor([config.tokenizer.token_to_id(config.intent2cls_id[intent])] + code).unsqueeze(0).cuda()\n",
    "    input_exemplar = torch.tensor(exemplar[intent]).unsqueeze(0).cuda()\n",
    "    code_valid_len = torch.tensor([code_valid_len]).cuda()\n",
    "    exemplar_valid_len = torch.tensor([len(exemplar[intent])]).cuda()\n",
    "    generator.eval()\n",
    "    pred = generator(input_code, input_exemplar, bos, code_valid_len, exemplar_valid_len, input_intent)\n",
    "    pred = config.tokenizer.decode(pred[0])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db135d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code:\n",
      " public int hashCode(){\n",
      "  return value.hashCode();\n",
      "}\n",
      "what: generates a hash code .\n",
      "why: generates code for this object .\n",
      "how-it-is-done: a method that generates a hashcode based on the contents of the string representations .\n",
      "usage: this method is used when this class is used as the code .\n",
      "property: return a hashcode for this text attribute .\n",
      "=============================================================================\n",
      "code:\n",
      " protected void writeQualifiedName(String nsAlias,String name) throws IOException {\n",
      "  if (nsAlias != null && nsAlias.length() > 0) {\n",
      "    writer.write(nsAlias);\n",
      "    writer.write(':');\n",
      "  }\n",
      "  writer.write(name);\n",
      "}\n",
      "what: writes a qualified name to a file .\n",
      "why: writes the beginning of the generated name to the given alias .\n",
      "how-it-is-done: copy a qualified name , using the given class .\n",
      "usage: below method will be used to write the idex file\n",
      "property: returns a managed name path holding the value of the specified string .\n",
      "=============================================================================\n",
      "code:\n",
      " <T>List<T> onFind(Class<T> modelClass,String[] columns,String[] conditions,String orderBy,String limit,boolean isEager){\n",
      "  BaseUtility.checkConditionsCorrect(conditions);\n",
      "  List<T> dataList=query(modelClass,columns,getWhereClause(conditions),getWhereArgs(conditions),null,null,orderBy,limit,getForeignKeyAssociations(modelClass.getName(),isEager));\n",
      "  return dataList;\n",
      "}\n",
      "what: handles the native query of the given table .\n",
      "why: the open interface for other classes in crud package to query the first record in a table .\n",
      "how-it-is-done: finds genericvalues by the conditions specified in the backwards conditions object , the where clause is the product of each of the type .\n",
      "usage: method modified just override here before executing your test cases .\n",
      "property: returns the order of the order specified\n",
      "=============================================================================\n",
      "code:\n",
      " private boolean isAgentEmpty(Agent agent){\n",
      "  if (agent != null) {\n",
      "    String first=agent.getFirstName();\n",
      "    String last=agent.getLastName();\n",
      "    String email=agent.getEmail();\n",
      "    String home=agent.getHomepage();\n",
      "    String org=agent.getOrganisation();\n",
      "    String phone=agent.getPhone();\n",
      "    String position=agent.getPosition();\n",
      "    String city=null;\n",
      "    String street=null;\n",
      "    String country=null;\n",
      "    String code=null;\n",
      "    String province=null;\n",
      "    Address address=agent.getAddress();\n",
      "    if (address != null) {\n",
      "      city=address.getCity();\n",
      "      street=address.getAddress();\n",
      "      country=address.getCountry();\n",
      "      code=address.getPostalCode();\n",
      "      province=address.getProvince();\n",
      "    }\n",
      "    String directory=null;\n",
      "    String identifier=null;\n",
      "    List<UserId> userIds=agent.getUserIds();\n",
      "    if (!userIds.isEmpty()) {\n",
      "      UserId userId=userIds.get(0);\n",
      "      directory=userId.getDirectory();\n",
      "      identifier=userId.getIdentifier();\n",
      "    }\n",
      "    return (Strings.isNullOrEmpty(city) && Strings.isNullOrEmpty(street) && Strings.isNullOrEmpty(country)&& Strings.isNullOrEmpty(code)&& Strings.isNullOrEmpty(province)&& Strings.isNullOrEmpty(first)&& Strings.isNullOrEmpty(last)&& Strings.isNullOrEmpty(email)&& Strings.isNullOrEmpty(home)&& Strings.isNullOrEmpty(org)&& Strings.isNullOrEmpty(phone)&& Strings.isNullOrEmpty(position)&& Strings.isNullOrEmpty(directory)&& Strings.isNullOrEmpty(identifier));\n",
      "  }\n",
      "  return true;\n",
      "}\n",
      "what: determine if the project page is empty .\n",
      "why: method to determine if the button is empty\n",
      "how-it-is-done: takes the user agent and add to the page , and add to the media playback .\n",
      "usage: method called from emds this method is used when running state .\n",
      "property: returns true if the user is empty , or false if not empty .\n",
      "=============================================================================\n",
      "code:\n",
      " public static byte[] calendarToRawBytes(Calendar timestamp,boolean honorDeviceTimeOffset){\n",
      "  if (honorDeviceTimeOffset) {\n",
      "    int offsetInHours=MiBandCoordinator.getDeviceTimeOffsetHours();\n",
      "    if (offsetInHours != 0) {\n",
      "      timestamp.add(Calendar.HOUR_OF_DAY,offsetInHours);\n",
      "    }\n",
      "  }\n",
      "  byte[] year=fromUint16(timestamp.get(Calendar.YEAR));\n",
      "  return new byte[]{year[0],year[1],fromUint8(timestamp.get(Calendar.MONTH) + 1),fromUint8(timestamp.get(Calendar.DATE)),fromUint8(timestamp.get(Calendar.HOUR_OF_DAY)),fromUint8(timestamp.get(Calendar.MINUTE)),fromUint8(timestamp.get(Calendar.SECOND)),dayOfWeekToRawBytes(timestamp),0};\n",
      "}\n",
      "what: converts a java time to a byte array .\n",
      "why: converts a calendar instance to a byte array for the current date and time in the given 10 .\n",
      "how-it-is-done: uses the standard algorithm to convert bytes received from the miband to a calendar object\n",
      "usage: this is the method is used in the future to draw the user is completely first time the second time .\n",
      "property: returns a byte array containing the current time .\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "# 3.prediction\n",
    "for i in range(len(input_code)):\n",
    "    print(\"code:\\n\", raw_code[i])\n",
    "    print(\"what:\", prediction(input_code[i], input_exemplar[i], 'what', code_valid_len[i]))\n",
    "    print(\"why:\", prediction(input_code[i], input_exemplar[i], 'why', code_valid_len[i]))\n",
    "    print(\"how-it-is-done:\", prediction(input_code[i], input_exemplar[i], 'done', code_valid_len[i]))\n",
    "    print(\"usage:\", prediction(input_code[i], input_exemplar[i], 'usage', code_valid_len[i]))\n",
    "    print(\"property:\", prediction(input_code[i], input_exemplar[i], 'property', code_valid_len[i]))\n",
    "    print(\"=============================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc9e74a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
